# Ralph Progress Log
---

## Codebase Patterns
- Config loading priority: env vars > .mat-config file > defaults
- Use dataclasses for Settings and similar config structures
- Type annotations required (strict mypy enabled in pyproject.toml)
- Use `ChatCompletionMessageParam` from `openai.types.chat` for typed message lists
- OllamaClient exposes both `chat()` (blocking) and `chat_stream()` (generator) methods
- BaseAgent uses dataclass with default_factory for mutable fields (client, history)
- Token estimation: ~4 chars per token (conservative for context window management)
- File operations: use `utils.file_ops` (sandboxed to project_dir), not raw file I/O
- FileOpsError raised for security violations (paths outside project dir)
- Logging: use `utils.logger` functions, not raw print() or logging module directly
- `log_agent_action()` and `log_agent_decision()` for consistent agent output formatting
- `StoryProgress` with context manager for build progress bars
- Specialized agents inherit from BaseAgent, add domain-specific state as dataclass fields
- AgentOrchestrator coordinates agents via `execute_task(task_type, message)` or `execute_workflow(steps)`
- TaskContext tracks context passing between agents; TaskResult wraps execution results
- `ralph.BuildLoop` is the autonomous build loop - use `run_build_loop()` convenience function
- PRDLoadError raised for prd.json validation errors; wrap json.JSONDecodeError with `from e`

---

## 2026-01-19 - US-001
- What was implemented: Configuration management module
- Files changed:
  - config/__init__.py (new)
  - config/settings.py (new)
  - pyproject.toml (new)
- **Learnings for future iterations:**
  - Settings class supports loading from env vars, .mat-config file, or defaults
  - Use `get_settings()` for global singleton access
  - Use `reload_settings()` to force reload of configuration
  - Environment variables: MAT_OLLAMA_URL, MAT_MODEL, MAT_PROJECT_DIR, MAT_VERBOSE, MAT_MAX_RETRIES, MAT_TIMEOUT
---

## 2026-01-19 - US-002
- What was implemented: Ollama integration layer with OpenAI-compatible API
- Files changed:
  - llm/__init__.py (new)
  - llm/client.py (new)
- **Learnings for future iterations:**
  - OllamaClient uses OpenAI SDK with `base_url="{ollama_url}/v1"` and dummy api_key="ollama"
  - Custom exceptions: `OllamaConnectionError`, `OllamaModelNotFoundError`, `OllamaResponseError`
  - Exponential backoff retry: `time.sleep(2**attempt)` for transient failures
  - Streaming uses generator pattern with `chat_stream()` yielding string chunks
  - `_list_available_models()` uses OpenAI `models.list()` endpoint for error messages
  - Conversation history format: `[{"role": "user"|"assistant", "content": "..."}]`
---

## 2026-01-19 - US-003
- What was implemented: Base agent class for all MAT agents
- Files changed:
  - agents/__init__.py (new)
  - agents/base.py (new)
- **Learnings for future iterations:**
  - BaseAgent is a dataclass with fields: name, role, system_prompt, client, conversation_history, max_context_tokens, max_retries
  - Uses Message dataclass for history entries: `Message(role="user"|"assistant", content="...")`
  - `chat(message)` handles history management, context truncation, and retries automatically
  - Context window management: reserves 1024 tokens for system prompt + new message, truncates oldest messages first
  - Token estimation uses ~4 chars/token heuristic
  - On non-recoverable errors (connection, model not found), user message is removed from history
  - Use `clear_history()` to reset conversation, `get_history_summary()` for stats
---

## 2026-01-19 - US-004
- What was implemented: File operations module with sandboxed read/write/list capabilities
- Files changed:
  - utils/__init__.py (new)
  - utils/file_ops.py (new)
- **Learnings for future iterations:**
  - Use `read_file(path)`, `write_file(path, content)`, `list_files(directory, pattern)` from utils.file_ops
  - All paths are sandboxed to `get_settings().project_dir` - paths outside are rejected with `FileOpsError`
  - `read_file()` returns empty string for non-existent files (with warning log)
  - Binary files (by extension) are skipped with warning, max file size is 1MB
  - `write_file()` auto-creates parent directories
  - `list_files()` supports glob patterns including recursive `**/*.py`
  - Optional `project_dir` parameter overrides global settings for testing
---

## 2026-01-19 - US-005
- What was implemented: Progress tracking and logging utilities
- Files changed:
  - utils/logger.py (new)
  - utils/__init__.py (updated - added logger exports)
- **Learnings for future iterations:**
  - Use `setup_logging(verbose=True/False)` to configure logging once at startup
  - `get_logger()` returns the MAT logger, auto-initializes if needed
  - `log_agent_action(agent_name, action, details)` for uniform agent output
  - `log_agent_decision(agent_name, decision, reasoning)` logs decisions with optional debug reasoning
  - `log_verbose(message, **kwargs)` only logs in verbose mode (DEBUG level)
  - `StoryProgress` is a context manager: `with create_progress_tracker(total, completed) as progress:`
  - Use `progress.begin_story()`, `progress.complete_story()`, `progress.fail_story()` to update
  - `log_build_start()` and `log_build_complete()` bracket the build with formatted output
  - Logs always go to both console (with rich formatting) and `build.log` file (plain text)
  - File logging is DEBUG level (verbose), console respects verbose setting
---

## 2026-01-19 - US-006
- What was implemented: Product Manager agent for discovery interviews
- Files changed:
  - agents/pm.py (new)
  - agents/__init__.py (updated - added ProductManagerAgent exports)
- **Learnings for future iterations:**
  - ProductManagerAgent inherits from BaseAgent and adds interview-specific logic
  - Uses DiscoveryPhase enum to track interview state: PROBLEM → USERS → FEATURES → SUCCESS → SCOPE → SUMMARY → COMPLETE
  - DiscoveryFindings dataclass stores responses for each phase
  - `start_interview()` resets state and returns opening message with first question
  - `process_response(user_response)` handles the interview flow:
    - Stores user response for current phase
    - Uses LLM to check if clarification is needed
    - Advances to next phase or asks follow-up question
  - `generate_summary()` uses LLM to create structured summary from findings
  - `get_findings()` returns dict of collected responses
  - `is_interview_complete()` checks if all phases done
  - Discovery questions stored in DISCOVERY_QUESTIONS dict, not hardcoded in methods
---

## 2026-01-19 - US-007
- What was implemented: Architect agent for technical solution design
- Files changed:
  - agents/architect.py (new)
  - agents/__init__.py (updated - added ArchitectAgent exports)
- **Learnings for future iterations:**
  - ArchitectAgent inherits from BaseAgent, adds ArchitectureDocument for state
  - Data classes: TechStackProposal, ComponentSpec, DataModel, ArchitectureDocument
  - `propose_tech_stack(requirements)` - parses LLM output into TechStackProposal
  - `identify_components(requirements)` - extracts components from LLM response (separated by ---)
  - `design_data_models(requirements)` - extracts models with fields and relationships
  - `design_api(requirements)` - extracts API endpoints (METHOD /path format)
  - `create_full_architecture(requirements)` - orchestrates full design process
  - `document_decision(decision, rationale)` - manually record architecture decisions
  - `get_architecture_markdown()` - converts current architecture to markdown
  - LLM output parsing: lines start with KEY:, blocks separated by ---
  - All dataclasses have `to_dict()` and relevant `to_markdown()` methods
---

## 2026-01-19 - US-008
- What was implemented: Developer agent for implementing user stories
- Files changed:
  - agents/developer.py (new)
  - agents/__init__.py (updated - added DeveloperAgent exports)
- **Learnings for future iterations:**
  - DeveloperAgent inherits from BaseAgent, adds current_story and context_files state
  - UserStory dataclass with `from_dict()` to load from prd.json format and `to_prompt()` for LLM
  - CodeFile dataclass represents generated code: path and content
  - ImplementationPlan dataclass: files_to_create, files_to_modify, approach
  - `set_story(story)` - sets story and clears history/context for fresh implementation
  - `read_context_file(path)` and `read_context_files(paths)` - load existing code for context
  - `find_related_files(pattern)` - uses `list_files()` to discover project files
  - `analyze_story()` - uses LLM to create ImplementationPlan with files and approach
  - `generate_code(file_path)` - generates new file content with story + context
  - `modify_code(file_path, existing)` - modifies existing file to satisfy story
  - `_extract_code(response)` - strips markdown code blocks from LLM output
  - `write_code_file(code_file)` - uses `write_file()` to persist generated code
  - `implement_story(story)` - orchestrates full implementation: plan → read context → generate → write
  - Agent prompts emphasize following existing patterns and keeping changes focused
---

## 2026-01-19 - US-009
- What was implemented: UX Designer agent for user interface design
- Files changed:
  - agents/ux.py (new)
  - agents/__init__.py (updated - added UXDesignerAgent exports, aliased ComponentSpec to avoid collision)
- **Learnings for future iterations:**
  - UXDesignerAgent inherits from BaseAgent, adds UXDocument for state
  - Data classes: ComponentSpec, UserFlowStep, UserFlow, InteractionSpec, UXDocument
  - Note: Both architect.py and ux.py have `ComponentSpec` - imported as `ArchComponentSpec` and `UXComponentSpec` in __init__.py
  - `create_component_spec(name, requirements)` - parses component specs with props, accessibility, states
  - `define_user_flow(name, requirements)` - parses flows with numbered steps (ACTION | RESULT format)
  - `define_interactions(context)` - parses interaction specs (TRIGGER, ACTION, FEEDBACK, A11Y)
  - `analyze_accessibility(requirements)` - generates WCAG 2.1 AA recommendations
  - `add_accessibility_note(note)` - manually add a11y notes
  - `create_full_ux_design(requirements)` - orchestrates overview, accessibility, flows, interactions
  - `get_ux_markdown()` - converts current UX document to markdown
  - `reset_ux_document()` - clears state and history for fresh design
  - System prompt emphasizes accessibility (WCAG 2.1 AA), keyboard navigation, screen readers
---

## 2026-01-19 - US-010
- What was implemented: Scrum Master agent for workflow management
- Files changed:
  - agents/scrum_master.py (new)
  - agents/__init__.py (updated - added ScrumMasterAgent exports)
- **Learnings for future iterations:**
  - ScrumMasterAgent inherits from BaseAgent, adds BuildQueue for state
  - StoryStatus enum: PENDING, IN_PROGRESS, BLOCKED, COMPLETED, FAILED
  - StoryState dataclass: tracks individual story with status, attempt count, failure reasons, blockers
  - StoryState.from_prd_story(dict) creates state from prd.json format
  - BuildQueue dataclass: manages list of stories, provides get_next_story(), get_summary()
  - BlockerAnalysis dataclass: severity, suggested_solutions, requires_human_intervention
  - `load_stories(prd_data)` - loads from prd.json dict into build queue
  - `get_next_story()` - returns next PENDING story, marks it IN_PROGRESS, increments attempt count
  - `mark_story_completed/failed/blocked(story_id)` - updates story status
  - `retry_story(story_id)` - resets FAILED/BLOCKED story to PENDING for retry
  - `analyze_blocker(story_id, error_context)` - uses LLM to analyze blocker and suggest solutions
  - `get_status_report()` - generates human-readable build status report
  - `should_continue_build(max_retries)` - determines if actionable stories remain
  - `get_build_summary()` - returns machine-readable dict with stats and story states
---

## 2026-01-19 - US-011
- What was implemented: QA Tester agent for verifying implementations
- Files changed:
  - agents/qa.py (new)
  - agents/__init__.py (updated - added QATesterAgent exports)
- **Learnings for future iterations:**
  - QATesterAgent inherits from BaseAgent, adds current_story and changed_files state
  - VerificationStatus enum: PASS, FAIL, SKIP, ERROR
  - CriterionResult dataclass: tracks verification of individual acceptance criterion
  - TypeCheckResult dataclass: wraps mypy results with passed flag, error count, error list
  - LintResult dataclass: wraps ruff results with passed flag, warning/error counts
  - VerificationReport dataclass: complete story verification with criteria, type check, lint results
  - `set_story(story, changed_files)` - sets story to verify and clears history
  - `verify_criterion(criterion, file_contents)` - uses LLM to verify single criterion
  - `run_type_check(path)` - runs mypy via subprocess, returns TypeCheckResult
  - `run_lint_check(path)` - runs ruff via subprocess, returns LintResult
  - `verify_story(story, changed_files)` - orchestrates full verification: criteria + type check + lint
  - `quick_verify()` - runs only type check and lint (no LLM verification)
  - `suggest_fixes(report)` - uses LLM to generate fix suggestions for failures
  - VerificationReport has `to_markdown()` for human-readable output
  - Type check skipped if mypy not installed (doesn't fail), lint skipped if ruff not installed
---

## 2026-01-19 - US-012
- What was implemented: Agent orchestrator for coordinating multiple agents
- Files changed:
  - orchestrator/__init__.py (new)
  - orchestrator/coordinator.py (new)
- **Learnings for future iterations:**
  - AgentOrchestrator inherits from BaseAgent, holds instances of all specialized agents
  - AgentType enum: PRODUCT_MANAGER, ARCHITECT, DEVELOPER, UX_DESIGNER, SCRUM_MASTER, QA_TESTER
  - TaskContext dataclass: tracks task_type, description, data dict, previous_agent, history
  - TaskResult dataclass: success flag, message, data dict, errors list
  - TASK_ROUTING dict maps task types to agent lists (e.g., "discovery" → [PM], "full_build" → [PM, ARCH, UX, DEV, QA])
  - `get_agent(agent_type)` retrieves agent instance by type
  - `determine_agent_for_task(task_type)` routes tasks using TASK_ROUTING or LLM fallback
  - `create_context(task_type, description)` creates new TaskContext for tracking
  - `pass_context_to_agent(agent_type, context)` formats context for agent handoff
  - `route_to_agent(agent_type, message, context)` sends message to agent with context
  - `execute_task(task_type, message)` routes to appropriate agents and returns TaskResult
  - `execute_workflow(workflow_steps)` executes list of (agent_type, message) tuples in sequence
  - `implement_story(story_data)` convenience method: Developer → QA with context passing
  - QA verify_story expects dict (story_data), not UserStory instance - use story_data directly
  - VerificationReport uses `overall_passed` not `passed` attribute
  - `get_status()` returns formatted status with all agent states
  - `reset()` clears all agent histories and current context
---

## 2026-01-19 - US-013
- What was implemented: PRD generation workflow using PM agent
- Files changed:
  - workflows/__init__.py (new)
  - workflows/prd_generator.py (new)
- **Learnings for future iterations:**
  - PRDGenerator orchestrates discovery interview and PRD generation from findings
  - UserStorySpec dataclass: id, title, description, acceptance_criteria
  - PRDDocument dataclass: project_name, overview, goals, user_stories, requirements, non_goals
  - `start_discovery()` begins PM agent interview, returns opening question
  - `process_user_input(response)` handles interview flow, returns next question or summary
  - `is_discovery_complete()` checks if all phases done
  - `generate_prd(project_name)` uses LLM to create structured PRD from findings
  - `save_prd(path)` writes PRD markdown to tasks/prd.md (default)
  - `run_full_workflow(responses, project_name)` convenience for automation/testing
  - PRD generation uses structured prompt with markers (PROJECT_NAME:, GOALS:, USER_STORIES:, etc.)
  - Parser uses nested function `save_current_story()` for clean state management
  - Always includes "Typecheck passes" in generated story criteria
---

## 2026-01-19 - US-014
- What was implemented: Story quality checker workflow for validating user stories
- Files changed:
  - workflows/story_quality.py (new)
  - workflows/__init__.py (updated - added StoryQualityChecker exports)
- **Learnings for future iterations:**
  - StoryQualityChecker validates stories before building with configurable checks
  - Data classes: QualityIssue, StorySpec, QualityReport
  - `load_stories(stories_data)` loads from list of dicts (prd.json format)
  - `check_all_stories()` runs length, criteria, and scope checks, returns QualityReport
  - `check_dependency_order()` uses LLM to analyze story dependencies
  - `split_story(story_id)` uses LLM to split large stories into smaller ones
  - `auto_fix_stories()` adds missing typecheck criteria and splits large stories
  - `run_full_check(stories_data, auto_fix, check_dependencies)` orchestrates full workflow
  - Issue types: length, criteria, scope, dependency
  - Constants: MAX_DESCRIPTION_LINES = 2, MIN_CRITERIA_COUNT = 2
  - Checks for vague words: "should work", "must be good", "etc", "and more"
  - QualityReport has `to_markdown()` for human-readable output
  - `get_fixed_stories_as_dicts()` returns stories in prd.json format
---

## 2026-01-19 - US-015
- What was implemented: Edge case analyzer workflow for identifying edge cases in user stories
- Files changed:
  - workflows/edge_cases.py (new)
  - workflows/__init__.py (updated - added EdgeCase, EdgeCaseAnalyzer, EdgeCaseReport exports)
- **Learnings for future iterations:**
  - EdgeCaseAnalyzer analyzes stories for four categories: input, state, error, security
  - EdgeCase dataclass: story_id, category, description, criterion, severity
  - EdgeCaseReport tracks: story_count, edge_cases list, updated_criteria dict
  - `load_stories(stories_data)` loads from list of dicts (prd.json format)
  - `analyze_input_edge_cases(story)` - empty values, boundaries, invalid formats, special chars
  - `analyze_state_edge_cases(story)` - race conditions, concurrent access, stale data
  - `analyze_error_edge_cases(story)` - network failures, validation errors, resource exhaustion
  - `analyze_security_edge_cases(story)` - injection, auth bypass, data exposure
  - `analyze_story(story)` runs all four category analyses on a single story
  - `analyze_all_stories()` analyzes all loaded stories, returns EdgeCaseReport
  - `add_edge_cases_to_criteria(max_per_story, min_severity)` adds findings to acceptance criteria
  - `run_full_analysis(stories_data, add_to_criteria, max_per_story, min_severity)` orchestrates full workflow
  - `get_updated_stories()` returns stories with added edge case criteria
  - LLM response format: `EDGE: [desc] | CRITERION: [crit] | SEVERITY: [sev]` or `NONE_FOUND:`
  - EdgeCaseReport has `to_markdown()` for human-readable output, `get_by_category()` and `get_by_story()`
---

## 2026-01-19 - US-016
- What was implemented: PRD to JSON converter workflow for Ralph build loop
- Files changed:
  - workflows/prd_to_json.py (new)
  - workflows/__init__.py (updated - added PRDJson, PRDToJsonConverter, StoryData exports)
- **Learnings for future iterations:**
  - PRDToJsonConverter converts PRD markdown (tasks/prd.md) to prd.json format
  - StoryData dataclass: id, title, description, acceptance_criteria, priority, passes (always false for new), notes
  - PRDJson dataclass: project, branch_name, description, user_stories list
  - `_normalize_branch_name(project)` converts project name to `ralph/kebab-case-name`
  - `load_prd(path)` reads PRD markdown from file (default: tasks/prd.md)
  - `parse(content, path)` parses markdown into PRDJson structure
  - `save(path)` writes prd.json (default: prd.json in project root)
  - `convert(input_path, output_path)` convenience method: load → parse → save
  - `set_project_info(project_name, branch_name, description)` manually override project info
  - `add_story(story)` adds StoryData or dict to PRD (passes always set to false)
  - `validate()` returns list of errors (duplicate IDs, missing fields, etc.)
  - Parses story headers: `### US-001: Title` or `## US-001 - Title`
  - Extracts description from "As a user, I want X" format
  - JSON uses camelCase keys: acceptanceCriteria, branchName, userStories
---

## 2026-01-19 - US-017
- What was implemented: Git operations module for Ralph build loop
- Files changed:
  - utils/git_ops.py (new)
  - utils/__init__.py (updated - added git_ops exports)
- **Learnings for future iterations:**
  - GitResult dataclass: success flag, message, output for standardized git command results
  - GitOpsError exception for git operation errors
  - `_run_git_command(args, cwd)` internal helper runs git with timeout and error handling
  - `is_git_repo(path)` checks if directory is inside a git work tree
  - `has_remote(remote_name, path)` checks if a remote (default: origin) is configured
  - `git_add(files, path)` stages files; accepts string or list, "-A" for all
  - `git_commit(message, path)` commits staged changes; returns failure if nothing staged
  - `git_push(remote, branch, path)` pushes to remote; skips gracefully if no remote configured
  - `git_status(path)` returns short status output
  - `auto_commit_story(story_id, story_title, changed_files, path)` convenience for committing story progress
  - `auto_commit_and_push(...)` combines commit + push; push failures don't fail overall operation
  - All operations check is_git_repo first and log warnings for non-repo directories
  - Push failures are logged but don't prevent build from continuing (graceful degradation)
  - 60-second timeout on all git operations to prevent hangs
---

## 2026-01-19 - US-018
- What was implemented: Ralph build loop core - autonomous build loop for implementing user stories
- Files changed:
  - ralph/__init__.py (new)
  - ralph/build_loop.py (new)
- **Learnings for future iterations:**
  - BuildLoop coordinates Developer and QA agents for story implementation
  - Data classes: BuildResult (final status), BuildLoopError/PRDLoadError (exceptions)
  - `BuildLoop.load_prd()` loads prd.json with validation (missing userStories, malformed JSON)
  - `BuildLoop.run()` is the main entry point for autonomous builds
  - `run_build_loop(prd_path, max_retries)` is a convenience function
  - Uses ScrumMasterAgent for tracking story status (PENDING/IN_PROGRESS/COMPLETED/FAILED)
  - Retry logic: up to max_retries (default 3) attempts per story before marking failed
  - `should_continue()` returns False when all remaining stories have failed (no actionable work)
  - Auto-commits after each successful story using `auto_commit_story()`
  - Progress tracked with `create_progress_tracker()` for visual feedback
  - `mark_story_passed(story_id)` updates prd.json and saves immediately
  - `get_remaining_count()` returns count of stories with passes=false
---
